{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4c5f3cd6",
   "metadata": {},
   "source": [
    "## Lectura del archivo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4fdd40fd",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import re\n",
    "import emoji\n",
    "with open(\"Tweets.txt\",encoding=\"utf8\") as archivo:\n",
    "    for linea in archivo:\n",
    "        linea = emoji.demojize(linea, delimiters=(\" \", \" \"))#ELIMINA LOS EMOJIS\n",
    "        patron = \"[.,;:\"\"''()?¿!¡-…]\"                      #QUITA LOS SIGNOS DE PUNTUACION\n",
    "        regex =re.compile(patron)\n",
    "        linea = regex.sub('',linea.lower())                #LOWER PARA DE MAYUSCULAS A MINUSCULAS\n",
    "        linea = re.sub(' +', ' ', linea)                   #QUITA LOS ESPACIOS DOBLRES\n",
    "        #CAMBIA LA ETIQUETA DE LOS USUARIO\n",
    "        words = linea.split(' ')                           #SE SEPARA LA LINEA EN PALABRAS\n",
    "        character = ''\n",
    "        for word in words:                                 #PARA CADA PALABRA EN PALABRAS\n",
    "            character = word[0]                            #TOMAMOS LA PRIMERA LETRA DE LA PALABRA Y SE ALMACENA EN CHARACTER\n",
    "            #ELIMINA A LOS USUARIO COLOCANDO LA TARJETA $user\n",
    "            if character == '@':\n",
    "                linea=linea.replace(str(word),\"$user\")\n",
    "            #ELIMINA A LOS HASHTAH COLOCANDO LA TARJETA $ht \n",
    "            if character == '#':\n",
    "                linea=linea.replace(str(word),\"$ht\")\n",
    "        file = open(\"Preprocesado.txt\", \"a\", encoding='utf-8')\n",
    "        file.write(linea)\n",
    "        file.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46a13c09",
   "metadata": {},
   "source": [
    "## REMOVER PALABRAS VACIAS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fb582a0",
   "metadata": {},
   "source": [
    "Se agregan Bibliotecas necesarias e imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0992d060",
   "metadata": {},
   "outputs": [],
   "source": [
    "import io  \n",
    "from nltk.corpus import stopwords  \n",
    "from nltk.tokenize import word_tokenize  \n",
    "stop_words = set(stopwords.words('Spanish'))  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57748727",
   "metadata": {},
   "source": [
    "Se abre el archivo generado anteriormente y se eliminan palabras vacias."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "057fd0e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"Preprocesado.txt\",encoding=\"utf8\") as file1:  \n",
    "    for linea in file1:                                #PARA CADA LINEA DE NUESTRO ARCHIVO SE HARÁ LO SIGUIENTE\n",
    "        words = linea.split()                          #SEPARAMOS LA LINEA CON EL SPLIT \n",
    "        for word in words:                             #PARA CADA PALABRA EN PALABRAS\n",
    "            if not word in stop_words:                 #SI NO ESTA EN STOP_WORDS\n",
    "                appendFile = open('PreprocesadoSinPV.txt', \"a\",encoding=\"utf8\")#ABRIMOS UN NUEVO ARCHIVO PARA ESCRIBIR EN EL\n",
    "                appendFile.write(word+\" \")             #ESCRIBIMOS LA PALABRA \n",
    "        appendFile.write(\"\\n\")                         #UN ENTER PARA EL FIN DE LA LINEA\n",
    "        appendFile.close() \n",
    "file1.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
